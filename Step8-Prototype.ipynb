{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b259687d-1612-455a-b1c0-ed0249320512",
   "metadata": {},
   "source": [
    "# Step 8: Prototyping.\n",
    "\n",
    "In the previous section we selected our base model, but did not finely tune it. We achieved a an accuracy of 99.1%, validation accuracy of 91.6%, and our F1 score was 0.915. In this section let's see if we can tune hyper parameters to improve on this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d1e422-0bc7-43eb-b6e4-593211c496e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8936b58-4460-44e4-a076-ba1c8b7092d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd3e81-6081-4c19-9998-7d52a82a46d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8.1: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f34c5c5-5755-4d57-a12b-bae616cbb47b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('E:/school/UCSD-ML-Capstone/images/Flowers5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import os.path\n",
    "\n",
    "data_dir =  pathlib.Path(os.path.abspath(\"images/Flowers5/\"))\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9760e7e1-911f-442a-bd2a-ec14ded6d52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs=25\n",
    "img_height = 192\n",
    "img_width = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea342d0-39d6-413d-9d81-1ac68fcc0b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1857 files belonging to 5 classes.\n",
      "Using 1486 files for training.\n",
      "Using 371 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(data_dir, validation_split=0.2, subset=\"both\", seed=123,\n",
    "                                                               image_size=(img_height, img_width), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05ab7f8-a6a2-47b7-a688-1f3ee3a4759b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Calceolaria', 'Daffodil', 'Freesia', 'Hibiscus', 'Iris']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "num_classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0079e02-739f-4c4c-83fb-aeb371b23e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_url = 'https://tfhub.dev/google/bit/s-r101x1/1'\n",
    "base_model = hub.KerasLayer(model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acadd9fb-1886-4544-851c-20041e25814a",
   "metadata": {},
   "source": [
    "## 8.2: Hyper parameter tuning.\n",
    "\n",
    "Here we test different hyper parameters and log their F1 score. This was based on this [codelab](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5b32f51-39d1-45cb-8922-8179898249c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2, 0.4))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam' ])) #, 'sgd'])) -- we already tested sgd, adam was better.\n",
    "\n",
    "METRIC_F1_SCORE = 'f1_score'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_F1_SCORE, display_name='F1 Score')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1cf1dab-5fd2-4632-8745-cd93f17364fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as sk_f1\n",
    "\n",
    "# Define our own function since we are working with batch datasets.\n",
    "def f1_score(model):\n",
    "    y_pred = []  # store predicted labels\n",
    "    y_true = []  # store true labels\n",
    "\n",
    "    # We iterate over the dataset to get the true label and input at the same time.\n",
    "    # Otherwise we will unintentionally shuffle the dataset.\n",
    "    for image_batch, label_batch in val_ds:\n",
    "        y_true.append(label_batch)\n",
    "        preds = model.predict(image_batch, verbose=0)\n",
    "        y_pred.append(np.argmax(preds, axis = - 1))\n",
    "\n",
    "    # convert the true and predicted labels into tensors\n",
    "    correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "    predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
    "    \n",
    "    return sk_f1(correct_labels, predicted_labels, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a362568-9010-425c-8db7-1a0f9d534f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Rescaling(1./255),\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "        layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        layers.Dense(num_classes),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=hparams[HP_OPTIMIZER],\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=1)\n",
    "    f1 = f1_score(model)\n",
    "    print(\"f1:\", f1)\n",
    "    return np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c5f3ea0-a8ed-47ab-9688-23f252fdb216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        f1 = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_F1_SCORE, f1, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "372f4a6b-7d96-4475-a658-02dd50cdd8de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba91630d-76a3-4865-8b18-a726a6dec4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-100\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 45s 336ms/step - loss: 0.9937 - accuracy: 0.6083 - val_loss: 0.5581 - val_accuracy: 0.8275\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.5346 - accuracy: 0.8001 - val_loss: 0.4249 - val_accuracy: 0.8679\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.4202 - accuracy: 0.8493 - val_loss: 0.3440 - val_accuracy: 0.8922\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.3485 - accuracy: 0.8668 - val_loss: 0.3048 - val_accuracy: 0.9057\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 261ms/step - loss: 0.2977 - accuracy: 0.8930 - val_loss: 0.2812 - val_accuracy: 0.9111\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.2652 - accuracy: 0.9092 - val_loss: 0.2629 - val_accuracy: 0.9030\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 13s 266ms/step - loss: 0.2235 - accuracy: 0.9253 - val_loss: 0.2346 - val_accuracy: 0.9111\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 13s 271ms/step - loss: 0.2122 - accuracy: 0.9226 - val_loss: 0.2222 - val_accuracy: 0.9191\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.1783 - accuracy: 0.9388 - val_loss: 0.2298 - val_accuracy: 0.9137\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.1786 - accuracy: 0.9374 - val_loss: 0.2046 - val_accuracy: 0.9245\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.1634 - accuracy: 0.9495 - val_loss: 0.2023 - val_accuracy: 0.9245\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.1503 - accuracy: 0.9475 - val_loss: 0.2002 - val_accuracy: 0.9218\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.1436 - accuracy: 0.9529 - val_loss: 0.2166 - val_accuracy: 0.9272\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.1270 - accuracy: 0.9569 - val_loss: 0.1839 - val_accuracy: 0.9299\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.1268 - accuracy: 0.9569 - val_loss: 0.1848 - val_accuracy: 0.9380\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 261ms/step - loss: 0.1140 - accuracy: 0.9576 - val_loss: 0.1985 - val_accuracy: 0.9434\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.1040 - accuracy: 0.9664 - val_loss: 0.2281 - val_accuracy: 0.9380\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.1077 - accuracy: 0.9590 - val_loss: 0.2042 - val_accuracy: 0.9380\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.0951 - accuracy: 0.9690 - val_loss: 0.1881 - val_accuracy: 0.9434\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.0993 - accuracy: 0.9637 - val_loss: 0.1821 - val_accuracy: 0.9542\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.0986 - accuracy: 0.9664 - val_loss: 0.2287 - val_accuracy: 0.9380\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.0874 - accuracy: 0.9690 - val_loss: 0.1788 - val_accuracy: 0.9407\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.0930 - accuracy: 0.9664 - val_loss: 0.1855 - val_accuracy: 0.9488\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.0774 - accuracy: 0.9717 - val_loss: 0.1888 - val_accuracy: 0.9488\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.0878 - accuracy: 0.9664 - val_loss: 0.1909 - val_accuracy: 0.9488\n",
      "f1: [0.98684211 0.93243243 0.91666667 0.9689441  0.93430657]\n",
      "--- Starting trial: run-101\n",
      "{'num_units': 16, 'dropout': 0.24000000000000002, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 24s 324ms/step - loss: 1.0248 - accuracy: 0.6124 - val_loss: 0.5507 - val_accuracy: 0.8491\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.6013 - accuracy: 0.7907 - val_loss: 0.4395 - val_accuracy: 0.8625\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.5022 - accuracy: 0.8190 - val_loss: 0.3631 - val_accuracy: 0.8733\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 260ms/step - loss: 0.4205 - accuracy: 0.8520 - val_loss: 0.3270 - val_accuracy: 0.8949\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.3591 - accuracy: 0.8654 - val_loss: 0.2672 - val_accuracy: 0.8976\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.3113 - accuracy: 0.8849 - val_loss: 0.2467 - val_accuracy: 0.9137\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.2694 - accuracy: 0.9024 - val_loss: 0.2237 - val_accuracy: 0.9191\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 265ms/step - loss: 0.2499 - accuracy: 0.9139 - val_loss: 0.2352 - val_accuracy: 0.9272\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.2306 - accuracy: 0.9219 - val_loss: 0.2080 - val_accuracy: 0.9326\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.1952 - accuracy: 0.9361 - val_loss: 0.2217 - val_accuracy: 0.9164\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.1793 - accuracy: 0.9347 - val_loss: 0.1918 - val_accuracy: 0.9380\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1767 - accuracy: 0.9307 - val_loss: 0.1784 - val_accuracy: 0.9380\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.1671 - accuracy: 0.9374 - val_loss: 0.1678 - val_accuracy: 0.9488\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.1728 - accuracy: 0.9354 - val_loss: 0.1715 - val_accuracy: 0.9353\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.1462 - accuracy: 0.9482 - val_loss: 0.1717 - val_accuracy: 0.9434\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.1551 - accuracy: 0.9435 - val_loss: 0.1745 - val_accuracy: 0.9326\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.1323 - accuracy: 0.9515 - val_loss: 0.1625 - val_accuracy: 0.9407\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.1402 - accuracy: 0.9421 - val_loss: 0.1705 - val_accuracy: 0.9461\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.1294 - accuracy: 0.9515 - val_loss: 0.1785 - val_accuracy: 0.9407\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.1262 - accuracy: 0.9468 - val_loss: 0.1655 - val_accuracy: 0.9407\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.1294 - accuracy: 0.9529 - val_loss: 0.1882 - val_accuracy: 0.9326\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.1234 - accuracy: 0.9542 - val_loss: 0.1642 - val_accuracy: 0.9326\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.1213 - accuracy: 0.9569 - val_loss: 0.1972 - val_accuracy: 0.9434\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.1033 - accuracy: 0.9630 - val_loss: 0.1597 - val_accuracy: 0.9434\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 13s 274ms/step - loss: 0.1076 - accuracy: 0.9576 - val_loss: 0.1723 - val_accuracy: 0.9515\n",
      "f1: [0.98684211 0.93959732 0.93150685 0.95597484 0.94117647]\n",
      "--- Starting trial: run-102\n",
      "{'num_units': 16, 'dropout': 0.28, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 23s 329ms/step - loss: 1.2805 - accuracy: 0.4812 - val_loss: 0.7532 - val_accuracy: 0.8410\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.8499 - accuracy: 0.6427 - val_loss: 0.6386 - val_accuracy: 0.8544\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.7470 - accuracy: 0.6810 - val_loss: 0.5062 - val_accuracy: 0.8706\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.6793 - accuracy: 0.7005 - val_loss: 0.4904 - val_accuracy: 0.8760\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.5995 - accuracy: 0.7301 - val_loss: 0.4058 - val_accuracy: 0.8841\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.5848 - accuracy: 0.7308 - val_loss: 0.3871 - val_accuracy: 0.8787\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.5538 - accuracy: 0.7369 - val_loss: 0.3771 - val_accuracy: 0.8922\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.5266 - accuracy: 0.7564 - val_loss: 0.3514 - val_accuracy: 0.8895\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.4947 - accuracy: 0.7665 - val_loss: 0.3336 - val_accuracy: 0.9003\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4747 - accuracy: 0.7820 - val_loss: 0.3544 - val_accuracy: 0.8922\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.4654 - accuracy: 0.7867 - val_loss: 0.3086 - val_accuracy: 0.9084\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4443 - accuracy: 0.7981 - val_loss: 0.3109 - val_accuracy: 0.9084\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.4262 - accuracy: 0.8129 - val_loss: 0.3097 - val_accuracy: 0.9084\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.4388 - accuracy: 0.8022 - val_loss: 0.2997 - val_accuracy: 0.9057\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.4184 - accuracy: 0.8183 - val_loss: 0.3024 - val_accuracy: 0.9003\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4169 - accuracy: 0.8136 - val_loss: 0.2658 - val_accuracy: 0.9111\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4026 - accuracy: 0.8163 - val_loss: 0.3009 - val_accuracy: 0.9030\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.4101 - accuracy: 0.8190 - val_loss: 0.2654 - val_accuracy: 0.9164\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.4045 - accuracy: 0.8109 - val_loss: 0.2600 - val_accuracy: 0.9191\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.3874 - accuracy: 0.8345 - val_loss: 0.2716 - val_accuracy: 0.9137\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.3527 - accuracy: 0.8540 - val_loss: 0.2655 - val_accuracy: 0.9137\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 261ms/step - loss: 0.3952 - accuracy: 0.8096 - val_loss: 0.2747 - val_accuracy: 0.9137\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.3707 - accuracy: 0.8371 - val_loss: 0.2456 - val_accuracy: 0.9272\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.3657 - accuracy: 0.8358 - val_loss: 0.2549 - val_accuracy: 0.9191\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.3657 - accuracy: 0.8445 - val_loss: 0.2746 - val_accuracy: 0.9164\n",
      "f1: [0.97402597 0.89655172 0.89051095 0.94339623 0.8707483 ]\n",
      "--- Starting trial: run-103\n",
      "{'num_units': 16, 'dropout': 0.32, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 22s 321ms/step - loss: 1.1278 - accuracy: 0.5437 - val_loss: 0.6480 - val_accuracy: 0.7925\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.7277 - accuracy: 0.7227 - val_loss: 0.4671 - val_accuracy: 0.8733\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.6397 - accuracy: 0.7490 - val_loss: 0.4089 - val_accuracy: 0.8760\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.4932 - accuracy: 0.8129 - val_loss: 0.3411 - val_accuracy: 0.8949\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4393 - accuracy: 0.8445 - val_loss: 0.2981 - val_accuracy: 0.9084\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.4252 - accuracy: 0.8405 - val_loss: 0.2951 - val_accuracy: 0.9164\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.4220 - accuracy: 0.8230 - val_loss: 0.2779 - val_accuracy: 0.9245\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.3899 - accuracy: 0.8439 - val_loss: 0.2822 - val_accuracy: 0.9057\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.3558 - accuracy: 0.8614 - val_loss: 0.2452 - val_accuracy: 0.9299\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.3349 - accuracy: 0.8701 - val_loss: 0.2331 - val_accuracy: 0.9218\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 13s 267ms/step - loss: 0.3115 - accuracy: 0.8728 - val_loss: 0.2306 - val_accuracy: 0.9299\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 261ms/step - loss: 0.3239 - accuracy: 0.8694 - val_loss: 0.2239 - val_accuracy: 0.9380\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.3064 - accuracy: 0.8822 - val_loss: 0.2618 - val_accuracy: 0.9030\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 261ms/step - loss: 0.2685 - accuracy: 0.8822 - val_loss: 0.2311 - val_accuracy: 0.9326\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 13s 264ms/step - loss: 0.2756 - accuracy: 0.8910 - val_loss: 0.2277 - val_accuracy: 0.9272\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 260ms/step - loss: 0.2701 - accuracy: 0.8856 - val_loss: 0.2305 - val_accuracy: 0.9245\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.2550 - accuracy: 0.9011 - val_loss: 0.2356 - val_accuracy: 0.9272\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.2549 - accuracy: 0.9017 - val_loss: 0.2152 - val_accuracy: 0.9299\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.2627 - accuracy: 0.8937 - val_loss: 0.2196 - val_accuracy: 0.9272\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.2296 - accuracy: 0.9118 - val_loss: 0.2169 - val_accuracy: 0.9272\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 13s 266ms/step - loss: 0.2243 - accuracy: 0.9038 - val_loss: 0.2286 - val_accuracy: 0.9272\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.2208 - accuracy: 0.9159 - val_loss: 0.2281 - val_accuracy: 0.9353\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 261ms/step - loss: 0.2436 - accuracy: 0.9011 - val_loss: 0.2144 - val_accuracy: 0.9353\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.2019 - accuracy: 0.9206 - val_loss: 0.2068 - val_accuracy: 0.9461\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.2176 - accuracy: 0.9199 - val_loss: 0.2310 - val_accuracy: 0.9326\n",
      "f1: [0.97368421 0.89795918 0.91034483 0.95061728 0.92647059]\n",
      "--- Starting trial: run-104\n",
      "{'num_units': 16, 'dropout': 0.36, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 23s 320ms/step - loss: 1.4285 - accuracy: 0.3728 - val_loss: 1.0294 - val_accuracy: 0.5526\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 1.0879 - accuracy: 0.5330 - val_loss: 0.7665 - val_accuracy: 0.7332\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.8699 - accuracy: 0.6655 - val_loss: 0.6744 - val_accuracy: 0.8625\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 255ms/step - loss: 0.8448 - accuracy: 0.6716 - val_loss: 0.5791 - val_accuracy: 0.8841\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.7790 - accuracy: 0.6783 - val_loss: 0.5102 - val_accuracy: 0.8841\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.7136 - accuracy: 0.7086 - val_loss: 0.4376 - val_accuracy: 0.9084\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.6939 - accuracy: 0.7046 - val_loss: 0.4070 - val_accuracy: 0.9191\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.6711 - accuracy: 0.7221 - val_loss: 0.4131 - val_accuracy: 0.9218\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.6209 - accuracy: 0.7497 - val_loss: 0.3810 - val_accuracy: 0.9245\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.6106 - accuracy: 0.7503 - val_loss: 0.3441 - val_accuracy: 0.9326\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.6149 - accuracy: 0.7476 - val_loss: 0.3264 - val_accuracy: 0.9299\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.5726 - accuracy: 0.7672 - val_loss: 0.3417 - val_accuracy: 0.9137\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.5836 - accuracy: 0.7537 - val_loss: 0.3065 - val_accuracy: 0.9353\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.5509 - accuracy: 0.7759 - val_loss: 0.2969 - val_accuracy: 0.9191\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.5530 - accuracy: 0.7873 - val_loss: 0.3203 - val_accuracy: 0.9380\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.5054 - accuracy: 0.8008 - val_loss: 0.3002 - val_accuracy: 0.9137\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.5129 - accuracy: 0.8069 - val_loss: 0.2969 - val_accuracy: 0.9218\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.5028 - accuracy: 0.8055 - val_loss: 0.2744 - val_accuracy: 0.9272\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.4829 - accuracy: 0.8116 - val_loss: 0.3038 - val_accuracy: 0.9434\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.4462 - accuracy: 0.8284 - val_loss: 0.2781 - val_accuracy: 0.9299\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 260ms/step - loss: 0.4984 - accuracy: 0.8096 - val_loss: 0.2859 - val_accuracy: 0.9272\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.4603 - accuracy: 0.8203 - val_loss: 0.2706 - val_accuracy: 0.9326\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4645 - accuracy: 0.8197 - val_loss: 0.2626 - val_accuracy: 0.9353\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4646 - accuracy: 0.8264 - val_loss: 0.2681 - val_accuracy: 0.9326\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4438 - accuracy: 0.8264 - val_loss: 0.2559 - val_accuracy: 0.9353\n",
      "f1: [0.98039216 0.92517007 0.89795918 0.9375     0.93333333]\n",
      "--- Starting trial: run-105\n",
      "{'num_units': 16, 'dropout': 0.4, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 22s 318ms/step - loss: 1.2288 - accuracy: 0.5013 - val_loss: 0.7498 - val_accuracy: 0.7844\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.8137 - accuracy: 0.6824 - val_loss: 0.5443 - val_accuracy: 0.8814\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.6868 - accuracy: 0.7322 - val_loss: 0.4496 - val_accuracy: 0.8625\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.6296 - accuracy: 0.7503 - val_loss: 0.3766 - val_accuracy: 0.9003\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.5765 - accuracy: 0.7651 - val_loss: 0.3464 - val_accuracy: 0.9164\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.5519 - accuracy: 0.7759 - val_loss: 0.3363 - val_accuracy: 0.9164\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.5150 - accuracy: 0.7921 - val_loss: 0.3011 - val_accuracy: 0.9191\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.4927 - accuracy: 0.7934 - val_loss: 0.3046 - val_accuracy: 0.9030\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.4437 - accuracy: 0.8183 - val_loss: 0.2880 - val_accuracy: 0.9245\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4396 - accuracy: 0.8230 - val_loss: 0.2491 - val_accuracy: 0.9272\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 252ms/step - loss: 0.4140 - accuracy: 0.8324 - val_loss: 0.2409 - val_accuracy: 0.9326\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.4018 - accuracy: 0.8405 - val_loss: 0.2366 - val_accuracy: 0.9380\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.3820 - accuracy: 0.8486 - val_loss: 0.2216 - val_accuracy: 0.9380\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 253ms/step - loss: 0.4086 - accuracy: 0.8351 - val_loss: 0.2526 - val_accuracy: 0.9353\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 254ms/step - loss: 0.3723 - accuracy: 0.8560 - val_loss: 0.2099 - val_accuracy: 0.9434\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.3690 - accuracy: 0.8479 - val_loss: 0.2184 - val_accuracy: 0.9326\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 256ms/step - loss: 0.3322 - accuracy: 0.8782 - val_loss: 0.1961 - val_accuracy: 0.9407\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 260ms/step - loss: 0.3720 - accuracy: 0.8620 - val_loss: 0.1767 - val_accuracy: 0.9434\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.3251 - accuracy: 0.8789 - val_loss: 0.1971 - val_accuracy: 0.9380\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3089 - accuracy: 0.8809 - val_loss: 0.1820 - val_accuracy: 0.9434\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3316 - accuracy: 0.8694 - val_loss: 0.1756 - val_accuracy: 0.9434\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3176 - accuracy: 0.8809 - val_loss: 0.1783 - val_accuracy: 0.9407\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3267 - accuracy: 0.8795 - val_loss: 0.2024 - val_accuracy: 0.9407\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3159 - accuracy: 0.8782 - val_loss: 0.1834 - val_accuracy: 0.9380\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3168 - accuracy: 0.8775 - val_loss: 0.1770 - val_accuracy: 0.9353\n",
      "f1: [0.97402597 0.91891892 0.91428571 0.9375     0.92857143]\n",
      "--- Starting trial: run-106\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 20s 302ms/step - loss: 0.9906 - accuracy: 0.6225 - val_loss: 0.5696 - val_accuracy: 0.8194\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.4850 - accuracy: 0.8311 - val_loss: 0.3868 - val_accuracy: 0.8814\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.3257 - accuracy: 0.8950 - val_loss: 0.3454 - val_accuracy: 0.8787\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.2686 - accuracy: 0.9085 - val_loss: 0.2678 - val_accuracy: 0.9030\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.2031 - accuracy: 0.9367 - val_loss: 0.2880 - val_accuracy: 0.9218\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.1812 - accuracy: 0.9502 - val_loss: 0.2421 - val_accuracy: 0.9137\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1395 - accuracy: 0.9603 - val_loss: 0.2110 - val_accuracy: 0.9272\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1165 - accuracy: 0.9670 - val_loss: 0.1964 - val_accuracy: 0.9272\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.1081 - accuracy: 0.9711 - val_loss: 0.2095 - val_accuracy: 0.9272\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0859 - accuracy: 0.9791 - val_loss: 0.1923 - val_accuracy: 0.9191\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0709 - accuracy: 0.9845 - val_loss: 0.1937 - val_accuracy: 0.9272\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0616 - accuracy: 0.9852 - val_loss: 0.1907 - val_accuracy: 0.9380\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0594 - accuracy: 0.9845 - val_loss: 0.1930 - val_accuracy: 0.9326\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0561 - accuracy: 0.9859 - val_loss: 0.2016 - val_accuracy: 0.9326\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.2003 - val_accuracy: 0.9299\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0484 - accuracy: 0.9886 - val_loss: 0.2049 - val_accuracy: 0.9353\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0395 - accuracy: 0.9899 - val_loss: 0.1634 - val_accuracy: 0.9326\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.1764 - val_accuracy: 0.9380\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0367 - accuracy: 0.9926 - val_loss: 0.2078 - val_accuracy: 0.9272\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0272 - accuracy: 0.9973 - val_loss: 0.1757 - val_accuracy: 0.9434\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0319 - accuracy: 0.9933 - val_loss: 0.1737 - val_accuracy: 0.9407\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0348 - accuracy: 0.9906 - val_loss: 0.1653 - val_accuracy: 0.9380\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0334 - accuracy: 0.9899 - val_loss: 0.1631 - val_accuracy: 0.9434\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.1518 - val_accuracy: 0.9434\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0221 - accuracy: 0.9960 - val_loss: 0.1809 - val_accuracy: 0.9461\n",
      "f1: [0.96774194 0.91780822 0.92957746 0.95652174 0.95652174]\n",
      "--- Starting trial: run-107\n",
      "{'num_units': 32, 'dropout': 0.24000000000000002, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 20s 304ms/step - loss: 0.9928 - accuracy: 0.6144 - val_loss: 0.5068 - val_accuracy: 0.8437\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.5089 - accuracy: 0.8197 - val_loss: 0.3777 - val_accuracy: 0.8868\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3836 - accuracy: 0.8560 - val_loss: 0.3273 - val_accuracy: 0.8895\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.3060 - accuracy: 0.8957 - val_loss: 0.2647 - val_accuracy: 0.9191\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2554 - accuracy: 0.9192 - val_loss: 0.2461 - val_accuracy: 0.9299\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2161 - accuracy: 0.9293 - val_loss: 0.2491 - val_accuracy: 0.9164\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1855 - accuracy: 0.9421 - val_loss: 0.2486 - val_accuracy: 0.9272\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1636 - accuracy: 0.9502 - val_loss: 0.2113 - val_accuracy: 0.9245\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1555 - accuracy: 0.9475 - val_loss: 0.2173 - val_accuracy: 0.9326\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1309 - accuracy: 0.9596 - val_loss: 0.1978 - val_accuracy: 0.9353\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1061 - accuracy: 0.9724 - val_loss: 0.2229 - val_accuracy: 0.9353\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1044 - accuracy: 0.9711 - val_loss: 0.2050 - val_accuracy: 0.9272\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0939 - accuracy: 0.9711 - val_loss: 0.1977 - val_accuracy: 0.9353\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0873 - accuracy: 0.9751 - val_loss: 0.1947 - val_accuracy: 0.9434\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0732 - accuracy: 0.9785 - val_loss: 0.2046 - val_accuracy: 0.9353\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0731 - accuracy: 0.9825 - val_loss: 0.1810 - val_accuracy: 0.9434\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0619 - accuracy: 0.9818 - val_loss: 0.1701 - val_accuracy: 0.9461\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0647 - accuracy: 0.9825 - val_loss: 0.1690 - val_accuracy: 0.9380\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0560 - accuracy: 0.9838 - val_loss: 0.2077 - val_accuracy: 0.9380\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0526 - accuracy: 0.9838 - val_loss: 0.1924 - val_accuracy: 0.9407\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0543 - accuracy: 0.9845 - val_loss: 0.1611 - val_accuracy: 0.9461\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0494 - accuracy: 0.9872 - val_loss: 0.1749 - val_accuracy: 0.9488\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0440 - accuracy: 0.9886 - val_loss: 0.1875 - val_accuracy: 0.9488\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0429 - accuracy: 0.9859 - val_loss: 0.1812 - val_accuracy: 0.9515\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0420 - accuracy: 0.9845 - val_loss: 0.1874 - val_accuracy: 0.9434\n",
      "f1: [0.97402597 0.92715232 0.91549296 0.95597484 0.94117647]\n",
      "--- Starting trial: run-108\n",
      "{'num_units': 32, 'dropout': 0.28, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 20s 303ms/step - loss: 0.8986 - accuracy: 0.6420 - val_loss: 0.5174 - val_accuracy: 0.8437\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.5106 - accuracy: 0.8143 - val_loss: 0.3772 - val_accuracy: 0.8922\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.3705 - accuracy: 0.8694 - val_loss: 0.3327 - val_accuracy: 0.9003\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.3052 - accuracy: 0.9044 - val_loss: 0.2747 - val_accuracy: 0.9111\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.2340 - accuracy: 0.9273 - val_loss: 0.2648 - val_accuracy: 0.9218\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.2005 - accuracy: 0.9240 - val_loss: 0.2542 - val_accuracy: 0.9218\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1667 - accuracy: 0.9536 - val_loss: 0.2105 - val_accuracy: 0.9272\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1502 - accuracy: 0.9489 - val_loss: 0.2277 - val_accuracy: 0.9191\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.1649 - accuracy: 0.9502 - val_loss: 0.1939 - val_accuracy: 0.9461\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.1171 - accuracy: 0.9724 - val_loss: 0.1885 - val_accuracy: 0.9380\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.1051 - accuracy: 0.9670 - val_loss: 0.1649 - val_accuracy: 0.9434\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0976 - accuracy: 0.9751 - val_loss: 0.1998 - val_accuracy: 0.9272\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1007 - accuracy: 0.9684 - val_loss: 0.1852 - val_accuracy: 0.9326\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0819 - accuracy: 0.9744 - val_loss: 0.1793 - val_accuracy: 0.9380\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0873 - accuracy: 0.9731 - val_loss: 0.2161 - val_accuracy: 0.9380\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0859 - accuracy: 0.9744 - val_loss: 0.1661 - val_accuracy: 0.9542\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0747 - accuracy: 0.9778 - val_loss: 0.1420 - val_accuracy: 0.9488\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0574 - accuracy: 0.9825 - val_loss: 0.2217 - val_accuracy: 0.9299\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0565 - accuracy: 0.9838 - val_loss: 0.1702 - val_accuracy: 0.9407\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0590 - accuracy: 0.9852 - val_loss: 0.1964 - val_accuracy: 0.9380\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0531 - accuracy: 0.9798 - val_loss: 0.1937 - val_accuracy: 0.9380\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0410 - accuracy: 0.9879 - val_loss: 0.1576 - val_accuracy: 0.9434\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0514 - accuracy: 0.9865 - val_loss: 0.1774 - val_accuracy: 0.9461\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 0.2133 - val_accuracy: 0.9353\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 247ms/step - loss: 0.0391 - accuracy: 0.9899 - val_loss: 0.1807 - val_accuracy: 0.9461\n",
      "f1: [0.98039216 0.92715232 0.91970803 0.96855346 0.92957746]\n",
      "--- Starting trial: run-109\n",
      "{'num_units': 32, 'dropout': 0.32, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 21s 304ms/step - loss: 1.0898 - accuracy: 0.5713 - val_loss: 0.5853 - val_accuracy: 0.8464\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.6040 - accuracy: 0.7618 - val_loss: 0.4069 - val_accuracy: 0.8706\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.4683 - accuracy: 0.8257 - val_loss: 0.3383 - val_accuracy: 0.8949\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.4018 - accuracy: 0.8567 - val_loss: 0.3025 - val_accuracy: 0.9003\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3150 - accuracy: 0.8943 - val_loss: 0.2537 - val_accuracy: 0.9137\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.3101 - accuracy: 0.8869 - val_loss: 0.2378 - val_accuracy: 0.9299\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.2509 - accuracy: 0.9118 - val_loss: 0.2334 - val_accuracy: 0.9272\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2291 - accuracy: 0.9172 - val_loss: 0.2250 - val_accuracy: 0.9218\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2177 - accuracy: 0.9233 - val_loss: 0.1967 - val_accuracy: 0.9326\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1788 - accuracy: 0.9381 - val_loss: 0.1809 - val_accuracy: 0.9353\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1759 - accuracy: 0.9408 - val_loss: 0.1936 - val_accuracy: 0.9353\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1531 - accuracy: 0.9475 - val_loss: 0.1874 - val_accuracy: 0.9299\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1461 - accuracy: 0.9536 - val_loss: 0.1961 - val_accuracy: 0.9380\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1344 - accuracy: 0.9549 - val_loss: 0.1708 - val_accuracy: 0.9407\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1412 - accuracy: 0.9495 - val_loss: 0.2177 - val_accuracy: 0.9245\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1294 - accuracy: 0.9623 - val_loss: 0.1692 - val_accuracy: 0.9434\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1093 - accuracy: 0.9704 - val_loss: 0.1456 - val_accuracy: 0.9407\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1196 - accuracy: 0.9630 - val_loss: 0.1763 - val_accuracy: 0.9434\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1058 - accuracy: 0.9690 - val_loss: 0.1574 - val_accuracy: 0.9434\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1012 - accuracy: 0.9623 - val_loss: 0.1870 - val_accuracy: 0.9380\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0957 - accuracy: 0.9717 - val_loss: 0.1643 - val_accuracy: 0.9488\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0974 - accuracy: 0.9704 - val_loss: 0.2248 - val_accuracy: 0.9407\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0815 - accuracy: 0.9711 - val_loss: 0.1539 - val_accuracy: 0.9488\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0879 - accuracy: 0.9697 - val_loss: 0.1787 - val_accuracy: 0.9380\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0798 - accuracy: 0.9751 - val_loss: 0.1932 - val_accuracy: 0.9434\n",
      "f1: [0.97402597 0.90909091 0.92517007 0.94478528 0.96296296]\n",
      "--- Starting trial: run-110\n",
      "{'num_units': 32, 'dropout': 0.36, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 21s 306ms/step - loss: 1.0873 - accuracy: 0.5747 - val_loss: 0.6019 - val_accuracy: 0.8194\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.5757 - accuracy: 0.7887 - val_loss: 0.4644 - val_accuracy: 0.8598\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.4274 - accuracy: 0.8573 - val_loss: 0.3195 - val_accuracy: 0.8976\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.3765 - accuracy: 0.8647 - val_loss: 0.3043 - val_accuracy: 0.9084\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3304 - accuracy: 0.8843 - val_loss: 0.2720 - val_accuracy: 0.9057\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3024 - accuracy: 0.8917 - val_loss: 0.2400 - val_accuracy: 0.9191\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.2509 - accuracy: 0.9152 - val_loss: 0.2350 - val_accuracy: 0.9164\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.2064 - accuracy: 0.9320 - val_loss: 0.2295 - val_accuracy: 0.9218\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.2000 - accuracy: 0.9287 - val_loss: 0.2240 - val_accuracy: 0.9245\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1907 - accuracy: 0.9388 - val_loss: 0.2260 - val_accuracy: 0.9353\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1590 - accuracy: 0.9455 - val_loss: 0.2299 - val_accuracy: 0.9111\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1695 - accuracy: 0.9401 - val_loss: 0.2229 - val_accuracy: 0.9164\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1519 - accuracy: 0.9536 - val_loss: 0.2056 - val_accuracy: 0.9272\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1442 - accuracy: 0.9468 - val_loss: 0.1763 - val_accuracy: 0.9353\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1234 - accuracy: 0.9610 - val_loss: 0.1786 - val_accuracy: 0.9245\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1375 - accuracy: 0.9536 - val_loss: 0.1936 - val_accuracy: 0.9380\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1080 - accuracy: 0.9630 - val_loss: 0.2029 - val_accuracy: 0.9245\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.1115 - accuracy: 0.9596 - val_loss: 0.1941 - val_accuracy: 0.9299\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0999 - accuracy: 0.9643 - val_loss: 0.1783 - val_accuracy: 0.9461\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0837 - accuracy: 0.9738 - val_loss: 0.1968 - val_accuracy: 0.9434\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0911 - accuracy: 0.9711 - val_loss: 0.2029 - val_accuracy: 0.9380\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1003 - accuracy: 0.9677 - val_loss: 0.1991 - val_accuracy: 0.9353\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.0911 - accuracy: 0.9690 - val_loss: 0.1644 - val_accuracy: 0.9434\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0873 - accuracy: 0.9684 - val_loss: 0.1887 - val_accuracy: 0.9326\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.0791 - accuracy: 0.9717 - val_loss: 0.1869 - val_accuracy: 0.9434\n",
      "f1: [0.98039216 0.90540541 0.92857143 0.95121951 0.94890511]\n",
      "--- Starting trial: run-111\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'adam'}\n",
      "Epoch 1/25\n",
      "47/47 [==============================] - 39s 308ms/step - loss: 1.1027 - accuracy: 0.5727 - val_loss: 0.5896 - val_accuracy: 0.8329\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.6349 - accuracy: 0.7389 - val_loss: 0.4479 - val_accuracy: 0.8760\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.4926 - accuracy: 0.8082 - val_loss: 0.3685 - val_accuracy: 0.8976\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.3911 - accuracy: 0.8513 - val_loss: 0.3113 - val_accuracy: 0.9057\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.3567 - accuracy: 0.8694 - val_loss: 0.3083 - val_accuracy: 0.9084\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.3171 - accuracy: 0.8829 - val_loss: 0.2558 - val_accuracy: 0.9326\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.2622 - accuracy: 0.9166 - val_loss: 0.2537 - val_accuracy: 0.9326\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.2615 - accuracy: 0.9092 - val_loss: 0.2229 - val_accuracy: 0.9218\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.2340 - accuracy: 0.9125 - val_loss: 0.2233 - val_accuracy: 0.9461\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.1836 - accuracy: 0.9381 - val_loss: 0.2133 - val_accuracy: 0.9353\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1884 - accuracy: 0.9354 - val_loss: 0.1984 - val_accuracy: 0.9515\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1757 - accuracy: 0.9354 - val_loss: 0.2088 - val_accuracy: 0.9326\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.1616 - accuracy: 0.9475 - val_loss: 0.2032 - val_accuracy: 0.9380\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1428 - accuracy: 0.9475 - val_loss: 0.1991 - val_accuracy: 0.9407\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.1411 - accuracy: 0.9536 - val_loss: 0.1858 - val_accuracy: 0.9407\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1671 - accuracy: 0.9401 - val_loss: 0.1986 - val_accuracy: 0.9515\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.1524 - accuracy: 0.9462 - val_loss: 0.1683 - val_accuracy: 0.9434\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.1393 - accuracy: 0.9515 - val_loss: 0.1861 - val_accuracy: 0.9542\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1203 - accuracy: 0.9569 - val_loss: 0.1875 - val_accuracy: 0.9488\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.1237 - accuracy: 0.9556 - val_loss: 0.1861 - val_accuracy: 0.9515\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1168 - accuracy: 0.9590 - val_loss: 0.1813 - val_accuracy: 0.9434\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1072 - accuracy: 0.9590 - val_loss: 0.1781 - val_accuracy: 0.9461\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1127 - accuracy: 0.9576 - val_loss: 0.1672 - val_accuracy: 0.9542\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.0877 - accuracy: 0.9697 - val_loss: 0.1874 - val_accuracy: 0.9434\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 251ms/step - loss: 0.0970 - accuracy: 0.9664 - val_loss: 0.1560 - val_accuracy: 0.9488\n",
      "f1: [0.99337748 0.93959732 0.91780822 0.95652174 0.93333333]\n"
     ]
    }
   ],
   "source": [
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in np.linspace(\n",
    "        HP_DROPOUT.domain.min_value,\n",
    "        HP_DROPOUT.domain.max_value,\n",
    "        num=6,\n",
    "    ):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90134692-a730-42af-b4ab-f8cb8439c9eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8.3 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92573193-7fc2-470e-aa0d-c9d5f9367bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 26980), started 1:28:35 ago. (Use '!kill 26980' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3fb487be09eaaeb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3fb487be09eaaeb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f890c-0806-4d46-8160-22a8bcd49d02",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can use the Tensorboard to see how the parameters affected our outcome. Below is a screenshot so it can be easily viewed in GitHub.\n",
    "\n",
    "![Tensorboard](step8-tensorboard.png)\n",
    "\n",
    "From the board we can tell that 'adam' was better than 'sgd' in general. The dropout rate seems to have a big impact too, likely by reducing bias in our model. Let's see if we can narrow down on the dropout rate for the 'adam' optimizer. To do so I updated the code above and re-ran it to get some more results. The results are logged to file so the previous runs won't be forgotten.\n",
    "\n",
    "![Tensorboard 2](step8-tensorboard-2.png)\n",
    "\n",
    "It looks like the best hyper parameters were: \n",
    " * num_units = 16\n",
    " * dropout = 0.24\n",
    " * optimizer = adam\n",
    " \n",
    " We got an F1 score of 95, which is pretty good.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43389e9c-3ed3-4dd4-9de7-a0598f2502b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8.4: Final model\n",
    "\n",
    "Let's build the model with the best score from our hyper parameter test and graph its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "207dbe03-677f-4938-8211-a1ad6b36606c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "47/47 [==============================] - 21s 307ms/step - loss: 1.1673 - accuracy: 0.5390 - val_loss: 0.6967 - val_accuracy: 0.7817\n",
      "Epoch 2/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.7253 - accuracy: 0.7147 - val_loss: 0.5449 - val_accuracy: 0.8275\n",
      "Epoch 3/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.6018 - accuracy: 0.7645 - val_loss: 0.4181 - val_accuracy: 0.8841\n",
      "Epoch 4/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.4870 - accuracy: 0.8022 - val_loss: 0.3516 - val_accuracy: 0.8949\n",
      "Epoch 5/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.4154 - accuracy: 0.8479 - val_loss: 0.3518 - val_accuracy: 0.8787\n",
      "Epoch 6/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.3929 - accuracy: 0.8614 - val_loss: 0.3097 - val_accuracy: 0.9003\n",
      "Epoch 7/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.3450 - accuracy: 0.8742 - val_loss: 0.2764 - val_accuracy: 0.9164\n",
      "Epoch 8/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.3063 - accuracy: 0.8876 - val_loss: 0.2592 - val_accuracy: 0.9245\n",
      "Epoch 9/25\n",
      "47/47 [==============================] - 12s 248ms/step - loss: 0.3034 - accuracy: 0.8890 - val_loss: 0.2402 - val_accuracy: 0.9272\n",
      "Epoch 10/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.2615 - accuracy: 0.9105 - val_loss: 0.2219 - val_accuracy: 0.9272\n",
      "Epoch 11/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2777 - accuracy: 0.9078 - val_loss: 0.2326 - val_accuracy: 0.9272\n",
      "Epoch 12/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2613 - accuracy: 0.9085 - val_loss: 0.2014 - val_accuracy: 0.9353\n",
      "Epoch 13/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2594 - accuracy: 0.9024 - val_loss: 0.2199 - val_accuracy: 0.9326\n",
      "Epoch 14/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.2381 - accuracy: 0.9145 - val_loss: 0.2170 - val_accuracy: 0.9299\n",
      "Epoch 15/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2178 - accuracy: 0.9266 - val_loss: 0.1933 - val_accuracy: 0.9326\n",
      "Epoch 16/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.2032 - accuracy: 0.9361 - val_loss: 0.1968 - val_accuracy: 0.9272\n",
      "Epoch 17/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1942 - accuracy: 0.9381 - val_loss: 0.1948 - val_accuracy: 0.9353\n",
      "Epoch 18/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1958 - accuracy: 0.9327 - val_loss: 0.1781 - val_accuracy: 0.9380\n",
      "Epoch 19/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1838 - accuracy: 0.9341 - val_loss: 0.2077 - val_accuracy: 0.9164\n",
      "Epoch 20/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1690 - accuracy: 0.9408 - val_loss: 0.1789 - val_accuracy: 0.9353\n",
      "Epoch 21/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1557 - accuracy: 0.9468 - val_loss: 0.1763 - val_accuracy: 0.9380\n",
      "Epoch 22/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1847 - accuracy: 0.9334 - val_loss: 0.1679 - val_accuracy: 0.9461\n",
      "Epoch 23/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1627 - accuracy: 0.9448 - val_loss: 0.1773 - val_accuracy: 0.9326\n",
      "Epoch 24/25\n",
      "47/47 [==============================] - 12s 250ms/step - loss: 0.1839 - accuracy: 0.9293 - val_loss: 0.1689 - val_accuracy: 0.9407\n",
      "Epoch 25/25\n",
      "47/47 [==============================] - 12s 249ms/step - loss: 0.1617 - accuracy: 0.9448 - val_loss: 0.1959 - val_accuracy: 0.9353\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(num_classes),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=1)\n",
    "f1 = f1_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e49c63-5eae-4239-8fa3-b3c67d8ac0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c25b62-fadd-47d4-a338-bf8fb87257a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
